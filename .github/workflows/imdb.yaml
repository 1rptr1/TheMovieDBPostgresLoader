name: IMDb Pipeline

on:
  workflow_dispatch:
  push:
    branches: [ main ]

jobs:
  imdb:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Download IMDb data
        run: |
          mkdir -p data
          echo "ðŸ“¥ Downloading IMDb data files..."
          wget -q https://datasets.imdbws.com/name.basics.tsv.gz -O - | gunzip > data/name.basics.tsv
          echo "âœ… Downloaded name.basics.tsv ($(wc -l < data/name.basics.tsv) lines)"
          wget -q https://datasets.imdbws.com/title.akas.tsv.gz -O - | gunzip > data/title.akas.tsv
          echo "âœ… Downloaded title.akas.tsv ($(wc -l < data/title.akas.tsv) lines)"
          wget -q https://datasets.imdbws.com/title.basics.tsv.gz -O - | gunzip > data/title.basics.tsv
          echo "âœ… Downloaded title.basics.tsv ($(wc -l < data/title.basics.tsv) lines)"
          wget -q https://datasets.imdbws.com/title.crew.tsv.gz -O - | gunzip > data/title.crew.tsv
          echo "âœ… Downloaded title.crew.tsv ($(wc -l < data/title.crew.tsv) lines)"
          wget -q https://datasets.imdbws.com/title.episode.tsv.gz -O - | gunzip > data/title.episode.tsv
          echo "âœ… Downloaded title.episode.tsv ($(wc -l < data/title.episode.tsv) lines)"
          wget -q https://datasets.imdbws.com/title.principals.tsv.gz -O - | gunzip > data/title.principals.tsv
          echo "âœ… Downloaded title.principals.tsv ($(wc -l < data/title.principals.tsv) lines)"
          wget -q https://datasets.imdbws.com/title.ratings.tsv.gz -O - | gunzip > data/title.ratings.tsv
          echo "âœ… Downloaded title.ratings.tsv ($(wc -l < data/title.ratings.tsv) lines)"
          echo "ðŸ“Š All data files downloaded successfully!"
          ls -la data/

      - name: Verify data files before starting container
        run: |
          echo "ðŸ” Verifying downloaded data files..."
          ls -la data/
          echo "ðŸ“Š Data file sizes:"
          for file in data/*.tsv; do
            if [ -f "$file" ]; then
              echo "$(basename "$file"): $(wc -l < "$file") lines, $(du -h "$file" | cut -f1)"
            fi
          done

      - name: Clean up any existing containers
        run: |
          docker compose -f docker-compose.yml -p imdb down -v || true
          docker system prune -f || true

      - name: Start Postgres with fresh container
        run: docker compose -f docker-compose.yml -p imdb up -d

      - name: Wait for Postgres
        run: |
          until docker exec imdb_postgres pg_isready -U imdb; do
            echo "Waiting for postgres..."
            sleep 5
          done

      - name: Debug directories
        run: |
          echo "ðŸ” Checking init scripts directory:"
          docker exec imdb_postgres ls -R /docker-entrypoint-initdb.d
          echo "ðŸ” Checking data directory:"
          docker exec imdb_postgres ls -la /imdb_data/ || echo "âŒ /imdb_data directory not found"
          echo "ðŸ” Checking data file sizes:"
          docker exec imdb_postgres sh -c 'for file in /imdb_data/*.tsv; do [ -f "$file" ] && echo "$(basename "$file"): $(wc -l < "$file") lines" || echo "$(basename "$file"): not found"; done' || echo "âŒ No data files found"

      - name: Show Postgres logs
        run: docker logs imdb_postgres

      - name: Load large tables with optimized memory usage
        run: |
          echo "â³ Starting optimized data loading..."
          
          # Function to load table in batches
          load_table() {
            local table=$1
            local file=$2
            local batch_size=500000  # Process 500K rows at a time
            
            echo "ðŸ“Š Loading $table in batches of $batch_size..."
            
            # Create a temporary file for the SQL script
            local sql_script=$(mktemp)
            
            cat > "$sql_script" << EOF
            DO \$\$
            DECLARE
              total_rows BIGINT;
              batch_count INT := 0;
              start_time TIMESTAMP;
            BEGIN
              -- Start timing
              start_time := clock_timestamp();
              
              -- Truncate target table
              EXECUTE format('TRUNCATE %I', '$table');
              RAISE NOTICE 'Truncated %', '$table';
              
              -- Create temporary table for loading
              EXECUTE format('CREATE TEMP TABLE temp_batch (LIKE %I)', '$table');
              
              -- Load data into temp table
              RAISE NOTICE 'Loading data into temp table...';
              EXECUTE format('COPY temp_batch FROM ''/imdb_data/%s'' 
                            WITH (DELIMITER E''\t'', HEADER true, NULL ''\N'', ENCODING ''UTF8'')', 
                            '$file');
              
              -- Process in batches
              LOOP
                EXECUTE format('INSERT INTO %I SELECT * FROM temp_batch 
                              WHERE ctid IN (SELECT ctid FROM temp_batch LIMIT %s OFFSET %s)',
                              '$table', $batch_size, batch_count * $batch_size);
                
                GET DIAGNOSTICS total_rows = ROW_COUNT;
                EXIT WHEN total_rows = 0;
                
                batch_count := batch_count + 1;
                RAISE NOTICE 'Processed batch %: % rows', batch_count, total_rows;
                
                -- Commit each batch to free memory
                COMMIT;
                BEGIN  -- Start a new transaction for the next batch
              END LOOP;
              
              -- Get final row count
              EXECUTE format('SELECT COUNT(*) FROM %I', '$table') INTO total_rows;
              
              -- Clean up
              DROP TABLE temp_batch;
              
              RAISE NOTICE 'Successfully loaded % rows into % in % seconds', 
                          total_rows, '$table', 
                          EXTRACT(EPOCH FROM (clock_timestamp() - start_time));
            EXCEPTION WHEN OTHERS THEN
              RAISE EXCEPTION 'Failed to load %: %', '$table', SQLERRM;
            END \$\$;
            EOF
            
            # Execute the SQL script
            docker exec -i imdb_postgres psql -U imdb -d imdb -v ON_ERROR_STOP=1 < "$sql_script"
            local status=$?
            
            # Clean up
            rm -f "$sql_script"
            
            return $status
          }
          
          # Load title_basics in batches
          load_table "title_basics" "title.basics.tsv" || exit 1
          
          # Load title_ratings in batches
          load_table "title_ratings" "title.ratings.tsv" || exit 1
          
          echo "âœ… Data loading completed"

      - name: Verify all tables created and loaded
        run: |
          echo "ðŸ” Checking all tables..."
          docker exec -i imdb_postgres psql -U imdb -d imdb -c "\dt"
          
          echo "ðŸ“Š Comprehensive data verification for all 7 IMDb tables..."
          docker exec -i imdb_postgres psql -U imdb -d imdb -c "
            SELECT 
              'name_basics' as table_name, COUNT(*) as row_count FROM name_basics
            UNION ALL
            SELECT 
              'title_basics' as table_name, COUNT(*) as row_count FROM title_basics  
            UNION ALL
            SELECT 
              'title_ratings' as table_name, COUNT(*) as row_count FROM title_ratings
            UNION ALL
            SELECT 
              'title_akas' as table_name, COUNT(*) as row_count FROM title_akas
            UNION ALL
            SELECT 
              'title_crew' as table_name, COUNT(*) as row_count FROM title_crew
            UNION ALL
            SELECT 
              'title_episode' as table_name, COUNT(*) as row_count FROM title_episode
            UNION ALL
            SELECT 
              'title_principals' as table_name, COUNT(*) as row_count FROM title_principals
            ORDER BY table_name;
          "
          
          echo "âœ… Quick verification check..."
          docker exec -i imdb_postgres psql -U imdb -d imdb -c "
            SELECT 'name_basics' as table_name, 
                   CASE WHEN EXISTS(SELECT 1 FROM name_basics LIMIT 1) THEN 'HAS_DATA' ELSE 'EMPTY' END as status;
          "
          
          echo "âœ… Data loading verification completed successfully!"

      - name: Show Postgres logs
        run: docker logs imdb_postgres

      - name: Run Chris Hemsworth query
        run: docker exec -i imdb_postgres psql -U imdb -d imdb -f /queries/chris_hemsworth_movies.sql